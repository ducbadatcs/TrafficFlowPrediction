{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3a766de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: keras in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (3.11.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from scikit-learn) (2.3.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (6.32.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (1.75.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: rich in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from keras) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from keras) (0.17.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from rich->keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from rich->keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\duc\\documents\\trafficflowprediction\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U torch scikit-learn pandas tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2e94f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up seed and device\n",
    "from typing import Any\n",
    "import numpy as np\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed = 100\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1570270",
   "metadata": {},
   "source": [
    "First, we'll read the relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d899a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data, fill missing data with 0\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./data/train.csv\", encoding=\"utf-8\").fillna(0)\n",
    "test_df = pd.read_csv(\"./data/test.csv\", encoding=\"utf-8\").fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702ca534",
   "metadata": {},
   "source": [
    "I just need to make sense of this transformation. Apparently, it removes the last column..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "40d1df54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "A[:, :-1] = [[1 2]\n",
      " [4 5]\n",
      " [7 8]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# remove the last column\n",
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "print(f\"A = {A}\")\n",
    "print(f\"A[:, :-1] = {A[:, :-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087bb1dd",
   "metadata": {},
   "source": [
    "Then, we'll process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "332d1b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5 Minutes</th>\n",
       "      <th>Lane 1 Flow (Veh/5 Minutes)</th>\n",
       "      <th># Lane Points</th>\n",
       "      <th>% Observed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04/01/2016 0:00</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04/01/2016 0:05</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/01/2016 0:10</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/01/2016 0:15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04/01/2016 0:20</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         5 Minutes  Lane 1 Flow (Veh/5 Minutes)  # Lane Points  % Observed\n",
       "0  04/01/2016 0:00                           12              1         100\n",
       "1  04/01/2016 0:05                           13              1         100\n",
       "2  04/01/2016 0:10                           11              1         100\n",
       "3  04/01/2016 0:15                           13              1         100\n",
       "4  04/01/2016 0:20                           10              1         100"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic data preview\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aba8792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "\n",
    "lag = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6154df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "train_col: str = \"Lane 1 Flow (Veh/5 Minutes)\"\n",
    "\n",
    "# fit scaler on training column\n",
    "\n",
    "# FIX: Fit scaler on TRAINING data, not test data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1)).fit(\n",
    "    train_df[train_col].values.reshape(-1, 1)  # ✅ Use train_df\n",
    ")\n",
    "\n",
    "train_flow = scaler.transform(train_df[train_col].values.reshape(-1, 1)).reshape(-1, 1)\n",
    "test_flow = scaler.transform(test_df[train_col].values.reshape(-1, 1)).reshape(-1, 1)\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "for i in range(lag, len(train_flow)):\n",
    "    train.append(train_flow[i - lag : i + 1])\n",
    "for i in range(lag, len(test_flow)):\n",
    "    test.append(test_flow[i - lag : i + 1])\n",
    "    \n",
    "train_array = np.array(train, )\n",
    "test_array = np.array(test,)\n",
    "np.random.shuffle(train_array)\n",
    "\n",
    "# train: all values other than last column\n",
    "# test: last column\n",
    "X_train = train_array[:, :-1]\n",
    "y_train = train_array[:, -1]\n",
    "X_test = test_array[:, :-1]\n",
    "y_test = test_array[:, -1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "65d4d98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (7764, 12, 1)\n",
      "Shape of X_test: (4308, 12, 1)\n",
      "Shape of y_train: (7764, 1)\n",
      "Shape of y_test: (4308, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59830a94",
   "metadata": {},
   "source": [
    "We then process the dataset to a suitable form of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "803b7a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch = 256\n",
    "epochs = 10 #test\n",
    "lr = 0.001\n",
    "val = 0.05 # validation ratio\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train).to(torch.float32) # Add feature dimension\n",
    "y_train_tensor = torch.from_numpy(y_train).to(torch.float32)\n",
    "X_test_tensor = torch.from_numpy(X_test).to(torch.float32)\n",
    "y_test_tensor = torch.from_numpy(y_test).to(torch.float32)\n",
    "\n",
    "val_size = int(len(X_train_tensor) * 0.05)\n",
    "X_val = X_train_tensor[-val_size:]\n",
    "y_val = y_train_tensor[-val_size:]\n",
    "X_train_split = X_train_tensor[:-val_size]\n",
    "y_train_split = y_train_tensor[:-val_size]\n",
    "\n",
    "train_dataset = TensorDataset(X_train_split, y_train_split)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cd6899",
   "metadata": {},
   "source": [
    "We implement the custom loss used in the original training: MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d1ed17e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor, optim\n",
    "\n",
    "class MAPELoss(nn.Module):\n",
    "    def __init__(self, eps: float = 1e-7):\n",
    "        super().__init__()\n",
    "        self.eps = eps  # avoid division by zero\n",
    "        \n",
    "    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        # Formula: mean( |(target - input) / clip(|target|, eps, inf)| ) * 100\n",
    "        denom = torch.clamp(torch.abs(target), min=self.eps)\n",
    "        loss = torch.mean(torch.abs((target - input) / denom)) * 100\n",
    "        return loss\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ebb81a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, units: list[int], *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.lstm1 = nn.LSTM(input_size=1, hidden_size=units[1], batch_first=True, num_layers=1)\n",
    "        self.lstm2 = nn.LSTM(input_size=units[1], hidden_size=units[2], batch_first=True, num_layers=1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear = nn.Linear(in_features = units[2], out_features=units[3])\n",
    "        \n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # lstm layer 1\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        \n",
    "        # keeps every sequence in the batch (:) but selects only the last \n",
    "        # time-step (-1) from the sequence dimension, leaving a tensor of shape \n",
    "        # (batch_size, hidden_size) for the final linear layer.\n",
    "        x = x[:, -1, :]\n",
    "        x = self.dropout(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "lstm = LSTM([12, 64, 64, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b811ecb1",
   "metadata": {},
   "source": [
    "Optimize the LSTM model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25dfc8e",
   "metadata": {},
   "source": [
    "Note that Criterion here is MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ef84863e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/600], Loss: 0.003918, Val Loss: 0.003348, MAPE: 27237.13%, Val MAPE: 20.30%\n",
      "Epoch [20/600], Loss: 0.003432, Val Loss: 0.002891, MAPE: 22354.42%, Val MAPE: 18.60%\n",
      "Epoch [30/600], Loss: 0.003397, Val Loss: 0.002735, MAPE: 19836.77%, Val MAPE: 19.47%\n",
      "Epoch [40/600], Loss: 0.003186, Val Loss: 0.003009, MAPE: 21085.36%, Val MAPE: 17.01%\n",
      "Epoch [50/600], Loss: 0.003158, Val Loss: 0.002965, MAPE: 14432.30%, Val MAPE: 16.50%\n",
      "Epoch [60/600], Loss: 0.003034, Val Loss: 0.002649, MAPE: 26060.27%, Val MAPE: 16.60%\n",
      "Epoch [70/600], Loss: 0.002983, Val Loss: 0.002683, MAPE: 27737.96%, Val MAPE: 17.98%\n",
      "Epoch [80/600], Loss: 0.002900, Val Loss: 0.002630, MAPE: 26245.36%, Val MAPE: 21.35%\n",
      "Epoch [90/600], Loss: 0.002897, Val Loss: 0.002561, MAPE: 23123.21%, Val MAPE: 17.70%\n",
      "Epoch [100/600], Loss: 0.002891, Val Loss: 0.002461, MAPE: 17680.54%, Val MAPE: 16.97%\n",
      "Epoch [110/600], Loss: 0.002808, Val Loss: 0.002437, MAPE: 27124.40%, Val MAPE: 18.12%\n",
      "Epoch [120/600], Loss: 0.002752, Val Loss: 0.002684, MAPE: 25892.37%, Val MAPE: 15.30%\n",
      "Epoch [130/600], Loss: 0.002782, Val Loss: 0.002704, MAPE: 16548.80%, Val MAPE: 16.66%\n",
      "Epoch [140/600], Loss: 0.002720, Val Loss: 0.002457, MAPE: 17416.22%, Val MAPE: 18.48%\n",
      "Epoch [150/600], Loss: 0.002724, Val Loss: 0.002474, MAPE: 29584.06%, Val MAPE: 16.72%\n",
      "Epoch [160/600], Loss: 0.002716, Val Loss: 0.002464, MAPE: 33043.28%, Val MAPE: 16.86%\n",
      "Epoch [170/600], Loss: 0.002731, Val Loss: 0.002515, MAPE: 29241.97%, Val MAPE: 19.07%\n",
      "Epoch [180/600], Loss: 0.002731, Val Loss: 0.002567, MAPE: 21710.69%, Val MAPE: 16.91%\n",
      "Epoch [190/600], Loss: 0.002802, Val Loss: 0.003244, MAPE: 23108.03%, Val MAPE: 28.31%\n",
      "Epoch [200/600], Loss: 0.002704, Val Loss: 0.002488, MAPE: 21330.03%, Val MAPE: 15.95%\n",
      "Epoch [210/600], Loss: 0.002661, Val Loss: 0.002483, MAPE: 27035.64%, Val MAPE: 15.95%\n",
      "Epoch [220/600], Loss: 0.002687, Val Loss: 0.002440, MAPE: 22501.28%, Val MAPE: 15.08%\n",
      "Epoch [230/600], Loss: 0.002662, Val Loss: 0.002494, MAPE: 25244.59%, Val MAPE: 15.86%\n",
      "Epoch [240/600], Loss: 0.002703, Val Loss: 0.002625, MAPE: 21709.01%, Val MAPE: 17.20%\n",
      "Epoch [250/600], Loss: 0.002694, Val Loss: 0.002412, MAPE: 27863.71%, Val MAPE: 17.56%\n",
      "Epoch [260/600], Loss: 0.002675, Val Loss: 0.002465, MAPE: 21602.04%, Val MAPE: 15.89%\n",
      "Epoch [270/600], Loss: 0.002633, Val Loss: 0.002638, MAPE: 25479.19%, Val MAPE: 18.73%\n",
      "Epoch [280/600], Loss: 0.002618, Val Loss: 0.002526, MAPE: 26823.18%, Val MAPE: 17.89%\n",
      "Epoch [290/600], Loss: 0.002567, Val Loss: 0.002499, MAPE: 42867.18%, Val MAPE: 22.88%\n",
      "Epoch [300/600], Loss: 0.002583, Val Loss: 0.002393, MAPE: 29042.32%, Val MAPE: 16.58%\n",
      "Epoch [310/600], Loss: 0.002583, Val Loss: 0.002484, MAPE: 20562.19%, Val MAPE: 16.40%\n",
      "Epoch [320/600], Loss: 0.002497, Val Loss: 0.002477, MAPE: 13982.55%, Val MAPE: 17.52%\n",
      "Epoch [330/600], Loss: 0.002512, Val Loss: 0.002376, MAPE: 24509.51%, Val MAPE: 15.53%\n",
      "Epoch [340/600], Loss: 0.002528, Val Loss: 0.002334, MAPE: 17730.35%, Val MAPE: 15.52%\n",
      "Epoch [350/600], Loss: 0.002525, Val Loss: 0.002446, MAPE: 22729.21%, Val MAPE: 21.52%\n",
      "Epoch [360/600], Loss: 0.002479, Val Loss: 0.002366, MAPE: 19492.05%, Val MAPE: 15.10%\n",
      "Epoch [370/600], Loss: 0.002505, Val Loss: 0.002374, MAPE: 23484.50%, Val MAPE: 18.09%\n",
      "Epoch [380/600], Loss: 0.002466, Val Loss: 0.002387, MAPE: 21782.62%, Val MAPE: 16.64%\n",
      "Epoch [390/600], Loss: 0.002456, Val Loss: 0.002424, MAPE: 15066.24%, Val MAPE: 15.76%\n",
      "Epoch [400/600], Loss: 0.002478, Val Loss: 0.002434, MAPE: 17278.00%, Val MAPE: 15.01%\n",
      "Epoch [410/600], Loss: 0.002466, Val Loss: 0.002289, MAPE: 21732.05%, Val MAPE: 15.24%\n",
      "Epoch [420/600], Loss: 0.002448, Val Loss: 0.002419, MAPE: 17041.82%, Val MAPE: 14.77%\n",
      "Epoch [430/600], Loss: 0.002471, Val Loss: 0.002380, MAPE: 17574.48%, Val MAPE: 20.66%\n",
      "Epoch [440/600], Loss: 0.002452, Val Loss: 0.002344, MAPE: 20489.47%, Val MAPE: 21.07%\n",
      "Epoch [450/600], Loss: 0.002400, Val Loss: 0.002286, MAPE: 20354.26%, Val MAPE: 18.09%\n",
      "Epoch [460/600], Loss: 0.002447, Val Loss: 0.002289, MAPE: 21599.86%, Val MAPE: 14.84%\n",
      "Epoch [470/600], Loss: 0.002413, Val Loss: 0.002334, MAPE: 22552.71%, Val MAPE: 18.35%\n",
      "Epoch [480/600], Loss: 0.002389, Val Loss: 0.002407, MAPE: 12047.64%, Val MAPE: 21.15%\n",
      "Epoch [490/600], Loss: 0.002434, Val Loss: 0.002322, MAPE: 22737.74%, Val MAPE: 15.49%\n",
      "Epoch [500/600], Loss: 0.002380, Val Loss: 0.002282, MAPE: 24963.67%, Val MAPE: 19.02%\n",
      "Epoch [510/600], Loss: 0.002440, Val Loss: 0.002381, MAPE: 23281.31%, Val MAPE: 23.74%\n",
      "Epoch [520/600], Loss: 0.002360, Val Loss: 0.002311, MAPE: 25463.30%, Val MAPE: 17.75%\n",
      "Epoch [530/600], Loss: 0.002396, Val Loss: 0.002369, MAPE: 21494.27%, Val MAPE: 16.22%\n",
      "Epoch [540/600], Loss: 0.002346, Val Loss: 0.002244, MAPE: 25521.55%, Val MAPE: 16.33%\n",
      "Epoch [550/600], Loss: 0.002360, Val Loss: 0.002271, MAPE: 26971.75%, Val MAPE: 16.50%\n",
      "Epoch [560/600], Loss: 0.002368, Val Loss: 0.002339, MAPE: 17287.70%, Val MAPE: 23.27%\n",
      "Epoch [570/600], Loss: 0.002342, Val Loss: 0.002223, MAPE: 32761.52%, Val MAPE: 19.53%\n",
      "Epoch [580/600], Loss: 0.002311, Val Loss: 0.002267, MAPE: 29477.68%, Val MAPE: 18.15%\n",
      "Epoch [590/600], Loss: 0.002309, Val Loss: 0.002265, MAPE: 24313.81%, Val MAPE: 15.65%\n",
      "Epoch [600/600], Loss: 0.002321, Val Loss: 0.002475, MAPE: 20161.15%, Val MAPE: 16.71%\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(lstm.parameters(), lr=lr)\n",
    "\n",
    "mse_metric = criterion\n",
    "mape_metric = MAPELoss()\n",
    "\n",
    "history = {'mse': [], 'val_mse': [], 'mape': [], 'val_mape': []}\n",
    "\n",
    "epochs = 600\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    lstm.train()\n",
    "    train_mse: float = 0\n",
    "    train_mape: float = 0\n",
    "    \n",
    "    # evaluate error over batch\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = lstm(batch_X)\n",
    "        mse = mse_metric(outputs, batch_y)\n",
    "        mape = mape_metric(outputs, batch_y)\n",
    "        \n",
    "        mse.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_mse += mse.item()\n",
    "        train_mape += mape.item()\n",
    "        \n",
    "    train_mse /= len(train_loader)\n",
    "    train_mape /= len(train_loader)\n",
    "    \n",
    "    # validation\n",
    "    lstm.eval()\n",
    "    with torch.no_grad():\n",
    "        X_val_device = X_val.to(device)\n",
    "        y_val_device = y_val.to(device)\n",
    "        val_outputs = lstm(X_val_device)\n",
    "        val_mse = mse_metric(val_outputs, y_val_device).item()\n",
    "        val_mape = mape_metric(val_outputs, y_val_device).item()\n",
    "        \n",
    "    history['mse'].append(train_mse)\n",
    "    history['val_mse'].append(val_mse)\n",
    "    history['mape'].append(train_mape)\n",
    "    history['val_mape'].append(val_mape)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], '\n",
    "              f'Loss: {train_mse:.6f}, Val Loss: {val_mse:.6f}, '\n",
    "              f'MAPE: {train_mape:.2f}%, Val MAPE: {val_mape:.2f}%')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "38f4b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optim.AdamW(lstm.parameters(), lr=0.001)\n",
    "lstm.to(device)\n",
    "\n",
    "epochs = 10\n",
    "for _ in range(epochs):\n",
    "    lstm.train()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1841cbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0987) tensor(-0.0317) tensor(-0.0537)\n"
     ]
    }
   ],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, units: list[int], *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.gru1 = nn.GRU(input_size=1, hidden_size=units[1], batch_first=True, num_layers=1)\n",
    "        self.gru2 = nn.GRU(input_size=units[1], hidden_size=units[2], batch_first=True, num_layers=1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear = nn.Linear(in_features = units[2], out_features=units[3])\n",
    "        # print(len(self.lstm1))\n",
    "        # print(len(self.lstm2))\n",
    "        # print(len(self.dropout))\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # lstm layer 1\n",
    "        x, _ = self.gru1(x)\n",
    "        x, _ = self.gru2(x)\n",
    "        \n",
    "        # keeps every sequence in the batch (:) but selects only the last \n",
    "        # time-step (-1) from the sequence dimension, leaving a tensor of shape \n",
    "        # (batch_size, hidden_size) for the final linear layer.\n",
    "        x = x[:, -1, :]\n",
    "        x = self.dropout(x)\n",
    "        return self.linear(x)\n",
    "    \n",
    "gru = GRU([12, 64, 64, 1])\n",
    "gru(\n",
    "    torch.from_numpy(X_train).to(dtype=torch.float32)\n",
    "    )\n",
    "\n",
    "for epoch in range(10):\n",
    "    gru.train()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = gru(torch.from_numpy(X_train[:10]).float())\n",
    "\n",
    "print(out.min(), out.max(), out.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac6089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abe48640",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TrafficFlowPrediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
